services:
  rag-app:
    build:
      context: ..
      dockerfile: docker/Dockerfile
    container_name: rag-app
    environment:
      HF_HOME: "/root/.cache/huggingface"           # Fester Ordner fuer HF Cache
      ANONYMIZED_TELEMETRY: "False"                 # ChromaDB Telemetrie deaktivieren
      RAG_PRINT_RESPONSES: "0"                      # Ausgabe der rag_querries [0/1]
    ports:
      - "8000:8000"
    volumes:
      - ../src/data:/src/data
      - ../src/scripts:/src/scripts
      - ../hf-cache:/root/.cache/huggingface
      - ../logs:/logs
      - ../emb_models:/emb_models
    depends_on:
      - ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [ gpu ]

  ollama:
    container_name: ollama
    image: ollama/ollama@sha256:d4188c1dfa870386a14e299976aed96daeb83876b69e1a852c9d09ea76463b9f
    ports:
      - "11434:11434"
    volumes:
      - ollama-data:/root/.ollama           # Caching Ollama Modelle
      - ./entrypoint.sh:/entrypoint.sh
    environment:
      OLLAMA_MODEL: "llama3:8b"         # Ollama Modell
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [ gpu ]
    entrypoint: ["/usr/bin/bash", "/entrypoint.sh"]

volumes:
  ollama-data: