services:
  rag-app:
    build:
      context: .
      dockerfile: Dockerfile.gmt
    container_name: rag-app
    environment:
      CHUNKING_STRATEGY: "simple"
      CHUNK_SIZE: 512
      CHUNK_OVERLAP: 64
      EMBEDDING_MODEL: "sentence-transformers/all-MiniLM-L6-v2"
      NORMALIZE_EMBEDDINGS: False
      HNSW_EF_CONSTRUCTION: 100
      HNSW_EF_SEARCH: 100
      HNSW_MAX_NEIGHBORS: 16
      METADATA_FILTER: False
      METADATA_ENHACEMENT: False
      POST_BM25_RERANK: False
      SIMULARITY_THRESHOLD: 3.0
      OLLAMA_MODEL: "llama3:8b"
      HF_HOME: "/root/.cache/huggingface"
      ANONYMIZED_TELEMETRY: "False"
    ports:
      - "8000:8000"
    depends_on:
      - ollama
    docker-run-args:
      - --gpus=all

  ollama:
    container_name: ollama
    image: ollama/ollama@sha256:d4188c1dfa870386a14e299976aed96daeb83876b69e1a852c9d09ea76463b9f
    docker-run-args:
      - -v ollama:/root/.ollama:ro
      - --gpus=all
    ports:
      - "11434:11434"
    environment:
      OLLAMA_MODEL: "llama3:8b"
    restart: unless-stopped
